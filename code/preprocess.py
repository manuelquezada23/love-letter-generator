import tensorflow as tf
import numpy as np
import pandas as pd
import nltk
from functools import reduce
from sklearn.utils import shuffle 
import os
import re
import pickle
import glob


def read_poems(data_path):
    """
    reads poem 
    """
    # https://stackoverflow.com/questions/7099290/how-to-ignore-hidden-files-using-os-listdir
    poems = glob.glob(os.path.join(data_path, '*'))
    print('Processing:', len(poems), 'files\n')

    poem_data = []
    purge = 0
    for poem in poems:
        poem_file_path = poem
        with open(poem_file_path, "r", encoding='utf-8') as poem_file:
            file = poem_file.read()
            file = file.encode('utf-8', errors='ignore').decode('utf-8')
            file = file.lower()
            file = re.sub(' +', ' ', file).strip()
            chars_remove = ['\t', '"', '%', '&', '\*', '\+', '/', '0', '1', '2', '3', '4', '¦',
                            '5', '6', '7', '8', '9', '=', '\[', '\]', '_',  '`', '{',
                            '¨', 'ª', '«', '²', 'º', '»', 'à', 'â', 'ã', 'ä', 'ç',
                            'è', 'ê', 'ì', 'ï', 'ò', 'ô', 'õ', 'ö', 'ü', '\xa0', '°', 
                            '~','¤','©','®','·','á','æ','é','ë','í','î','ð','ñ','ó','ø','ù','ú','û','侄', 'ý','þ','ā','ă','ć','č','đ','ī','œ','ś','ş','š','ţ','ũ','ū','ž','ơ','ư','ș','ț̣̀́̃̉','ά','έ','ή','ί','α','β','γ','δ','ε','ζ','η','θ','ι','κ','λ','μ','ν','ξ','ο','π','ρ','ς','σ','τ','υ','φ','χ','ψ','ω','ό','ύ','ώ','а','б','в','г','д','е','ж','з','и','й','к','л','м','н','о','п','р','с','т','у','х','ц','ч','ш','ы','ь','э','ю','я','ё','،','آ','ئ','ا','ب','ت','ج','ح','خ','د','ر','ز','س','ش','ص','ط','ع','غ','ف','ك','ل','م','ن','وِ','ٹ','پ','چ','ڑ','ک','گ','ں','ھ','ہ','ی','ے','۔ँं','अ','आ','इ','ई','उ','ए','ऐ','ओ','औ','क','ख','ग','घ','च','ज','झ','ट','ठ','ड','ण','त','थ','द','ध','न','प','फ','ब','भ','म','य','र','ल','व','श','ष','स','ह़ािीुूृेैॉोौ्','ग़','ज़','ड़','ढ़','फ़','।ঁং','অ','আ','ই','উ','এ','ও','ক','খ','গ','ঙ','চ','ছ','জ','ঝ','ঞ','ট','ড','ণ','ত','থ','দ','ধ','ন','প','ফ','ব','ভ','ম','য','র','ল','শ','স','হ়ািীুূেোৌ্','ৎଁଂ','ଅ','ଆ','ଉ','ଏ','କ','ଗ','ଚ','ଛ','ଜ','ଟ','ଠ','ଡ','ଣ','ତ','ଥ','ଦ','ଧ','ନ','ପ','ବ','ଭ','ମ','ଯ','ର','ଳ','ଶ','ସ','ହାିୀୁେୋ୍','ୟ','ୱ','ạ','ấ','ầ','ậ','ắ','ằ','ẻ','ế','ỉ','ọ','ỏ','ố','ồ','ộ','ớ','ờ','ở',' ','​','‌','–','—','―','“','”','„','•','€','™','−','─','│','▌','▐','▲','◆','○','●','★','☆','☻','♥','。','《','》','【','】','一','七','三','上','下','不','与','世','东','两','丧','中','丰','丹','为','乐','乘','九','书','争','二','于','云','五','交','享','京','亲','人','今','他','仙','代','们','优','会','传','伤','但','位','体','余','作','你','俏','儿','先','光','入','全','八','共','内','写','冶','冷','几','出','分','切','则','创','初','别','刻','前','剑','力','动','化','北','区','十','千','午','半','华','印','卷','厄','去','县','参','古','句','叶','号','合','同','后','吼','咆','和','咬','咽','哀','品','响','哭','哮','哽','唐','喘','喷','嚼','四','回','园','国','图','在','地','城','堪','境','墨','士','声','处','夕','外','多','夜','大','天','太','夫','失','夹','女','妈','姚','娥','子','字','孙','孟','安','宋','官','定','客','宣','宵','容','寂','富','对','寺','导','寿','少','尔','尘','就','山','岁','岸','己','已','市','师','希','席','常','平','年','广','府','座','开','弋','形','影','待','律','得','循','心','忆','志','快','怀','怒','思','恩','息','恸','悠','悲','情','惜','意','愿','慈','成','我','或','战','才','扭','承','抖','拉','挥','挽','描','摧','摸','撼','改','故','教','数','文','新','方','施','无','日','旦','早','时','旷','星','春','是','景','暖','暴','曲','更','曾','月','有','朝','未','朵','机','朽','李','束','条','来','板','构','林','枝','枯','柔','柳','树','栖','格','桃','桐','梦','梨','欲','歌','正','残','殡','每','比','毕','毫','氏','水','求','汉','江','池','汩','沉','沧','河','泊','法','泣','注','泪','泳','泼','洋','洞','津','活','流','浑','浓','海','涌','淌','淙','深','淹','温','游','湖','源','满','潺','灯','灵','炉','点','烟','然','照','熔','熠','爱','牡','狂','玉','珀','琢','瓦','瓶','生','由','男','画','界','疏','痛','白','百','的','皆','盘','盛','目','相','省','看','眼','睛','知','矫','磬','祁','祈','神','祭','秃','秋','种','稿','穴','空','穿','窗','章','端','笔','第','等','简','精','紫','繁','纸','经','绝','缘','缠','罗','美','翠','翻','联','育','胆','脉','臣','自','至','舌','色','芒','花','若','英','草','荣','荷','莱','莲','菊','萎','萦','落','著','蘸','虚','蛇','血','行','裴','裸','襄','西','见','规','觅','触','言','认','记','论','词','译','诗','谦','谷','象','赋','赝','走','起','轮','载','辈','达','过','运','这','进','远','连','迟','透','通','逝','速','遵','邀','酒','酬','酸','醉','醒','里','野','钟','银','铺','锁','锋','错','镜','长','门','间','闻','阳','阴','阵','陆','陶','雄','雅','雕','雪','雾','霜','霭','露','青','静','韧','音','韵','题','颤','风','飘','飙','饱','首','馨','马','魂','魄','默','龙','','！','（','）','，','：','？','💏','💐','💓'
            ]
            valid = False
            for char in chars_remove:
                # If the poem has a character in the remove set, we completely remove poem from corpus
                if char in file:
                    purge = purge + 1
                    break
                else:
                    valid = True

            if valid == True:
                chars_remove = '[' + ''.join(chars_remove) + ']'
                # Double checking that there are no characters left over
                file = re.sub(chars_remove, ' ', file)
                file = re.sub(' +', ' ', file).strip()
                poem_data.append({'file': poem_file_path,
                            'corpus': file})
    return poem_data

"""
cleans data from unnecessary stuff 
"""
def clean_data(corp):
    # Remove poems with less than 260 characters
    characters = [len(x['corpus']) for x in corp]
    indices = [x > 260 for x in characters]
    corp = list(np.array(corp)[np.array(indices)])

    # Remove poems with less than 8 lines or more than 50 lines
    lines = [len(x['corpus'].split('\n')) for x in corp]
    indices = [((x > 8) & (x < 50)) for x in lines]
    corp = list(np.array(corp)[np.array(indices)])

    # Remove poems with less than 30 words or more than 200 words
    words = [len(re.findall(r'\w+', x['corpus'])) for x in corp]
    indices = [((x > 30) & (x < 200)) for x in words]
    corp = list(np.array(corp)[np.array(indices)])


    all_text = str()
    for x in corp:
        all_text = all_text + x['corpus']

    # Remove strange characters

    chars_remove = ['\t', '"', '%', '&', '\*', '\+', '/', '0', '1', '2', '3', '4', '侄', '¦'
                    '5', '6', '7', '8', '9', '=', '\[', '\]', '_',  '`', '{',
                    '¨', 'ª', '«', '²', 'º', '»', 'à', 'â', 'ã', 'ä', 'ç',
                    'è', 'ê', 'ì', 'ï', 'ò', 'ô', 'õ', 'ö', 'ü', '\xa0', '°', 
                    '~','¤','©','®','·','á','æ','é','ë','í','î','ð','ñ','ó','ø','ù','ú','û','ý','þ','ā','ă','ć','č','đ','ī','œ','ś','ş','š','ţ','ũ','ū','ž','ơ','ư','ș','ț̣̀́̃̉','ά','έ','ή','ί','α','β','γ','δ','ε','ζ','η','θ','ι','κ','λ','μ','ν','ξ','ο','π','ρ','ς','σ','τ','υ','φ','χ','ψ','ω','ό','ύ','ώ','а','б','в','г','д','е','ж','з','и','й','к','л','м','н','о','п','р','с','т','у','х','ц','ч','ш','ы','ь','э','ю','я','ё','،','آ','ئ','ا','ب','ت','ج','ح','خ','د','ر','ز','س','ش','ص','ط','ع','غ','ف','ك','ل','م','ن','وِ','ٹ','پ','چ','ڑ','ک','گ','ں','ھ','ہ','ی','ے','۔ँं','अ','आ','इ','ई','उ','ए','ऐ','ओ','औ','क','ख','ग','घ','च','ज','झ','ट','ठ','ड','ण','त','थ','द','ध','न','प','फ','ब','भ','म','य','र','ल','व','श','ष','स','ह़ािीुूृेैॉोौ्','ग़','ज़','ड़','ढ़','फ़','।ঁং','অ','আ','ই','উ','এ','ও','ক','খ','গ','ঙ','চ','ছ','জ','ঝ','ঞ','ট','ড','ণ','ত','থ','দ','ধ','ন','প','ফ','ব','ভ','ম','য','র','ল','শ','স','হ়ািীুূেোৌ্','ৎଁଂ','ଅ','ଆ','ଉ','ଏ','କ','ଗ','ଚ','ଛ','ଜ','ଟ','ଠ','ଡ','ଣ','ତ','ଥ','ଦ','ଧ','ନ','ପ','ବ','ଭ','ମ','ଯ','ର','ଳ','ଶ','ସ','ହାିୀୁେୋ୍','ୟ','ୱ','ạ','ấ','ầ','ậ','ắ','ằ','ẻ','ế','ỉ','ọ','ỏ','ố','ồ','ộ','ớ','ờ','ở',' ','​','‌','–','—','―','“','”','„','•','€','™','−','─','│','▌','▐','▲','◆','○','●','★','☆','☻','♥','。','《','》','【','】','一','七','三','上','下','不','与','世','东','两','丧','中','丰','丹','为','乐','乘','九','书','争','二','于','云','五','交','享','京','亲','人','今','他','仙','代','们','优','会','传','伤','但','位','体','余','作','你','俏','儿','先','光','入','全','八','共','内','写','冶','冷','几','出','分','切','则','创','初','别','刻','前','剑','力','动','化','北','区','十','千','午','半','华','印','卷','厄','去','县','参','古','句','叶','号','合','同','后','吼','咆','和','咬','咽','哀','品','响','哭','哮','哽','唐','喘','喷','嚼','四','回','园','国','图','在','地','城','堪','境','墨','士','声','处','夕','外','多','夜','大','天','太','夫','失','夹','女','妈','姚','娥','子','字','孙','孟','安','宋','官','定','客','宣','宵','容','寂','富','对','寺','导','寿','少','尔','尘','就','山','岁','岸','己','已','市','师','希','席','常','平','年','广','府','座','开','弋','形','影','待','律','得','循','心','忆','志','快','怀','怒','思','恩','息','恸','悠','悲','情','惜','意','愿','慈','成','我','或','战','才','扭','承','抖','拉','挥','挽','描','摧','摸','撼','改','故','教','数','文','新','方','施','无','日','旦','早','时','旷','星','春','是','景','暖','暴','曲','更','曾','月','有','朝','未','朵','机','朽','李','束','条','来','板','构','林','枝','枯','柔','柳','树','栖','格','桃','桐','梦','梨','欲','歌','正','残','殡','每','比','毕','毫','氏','水','求','汉','江','池','汩','沉','沧','河','泊','法','泣','注','泪','泳','泼','洋','洞','津','活','流','浑','浓','海','涌','淌','淙','深','淹','温','游','湖','源','满','潺','灯','灵','炉','点','烟','然','照','熔','熠','爱','牡','狂','玉','珀','琢','瓦','瓶','生','由','男','画','界','疏','痛','白','百','的','皆','盘','盛','目','相','省','看','眼','睛','知','矫','磬','祁','祈','神','祭','秃','秋','种','稿','穴','空','穿','窗','章','端','笔','第','等','简','精','紫','繁','纸','经','绝','缘','缠','罗','美','翠','翻','联','育','胆','脉','臣','自','至','舌','色','芒','花','若','英','草','荣','荷','莱','莲','菊','萎','萦','落','著','蘸','虚','蛇','血','行','裴','裸','襄','西','见','规','觅','触','言','认','记','论','词','译','诗','谦','谷','象','赋','赝','走','起','轮','载','辈','达','过','运','这','进','远','连','迟','透','通','逝','速','遵','邀','酒','酬','酸','醉','醒','里','野','钟','银','铺','锁','锋','错','镜','长','门','间','闻','阳','阴','阵','陆','陶','雄','雅','雕','雪','雾','霜','霭','露','青','静','韧','音','韵','题','颤','风','飘','飙','饱','首','馨','马','魂','魄','默','龙','','！','（','）','，','：','？','💏','💐','💓'
    ]

    chars_remove = '[' + ''.join(chars_remove) + ']'
    # remove characters
    for doc in corp:
        doc['corpus'] = re.sub(chars_remove, ' ', doc['corpus'])
        doc['corpus'] = re.sub(' +', ' ', doc['corpus']).strip()

    # remove line breaks
    for doc in corp:
        for pattern in ['\r\r\n', '\r\n ', '\r\n', '\n\n', '\r']:
            doc['corpus'] = re.sub(pattern, '\n', doc['corpus'])

    # remove empty lines
    for doc in corp:
        doc['corpus'] = doc['corpus'] + '.$'

    return corp

"""
maps characters in a dictionary
"""
def get_vocabulary(corpus):

    all_text = str()
    for x in corpus:
        all_text = all_text + x['corpus']
    
    # from prev hw
    characters = sorted(list(set(all_text)))
    
    n_to_char = {n:char for n, char in enumerate(characters)}
    char_to_n = {char:n for n, char in enumerate(characters)}
    
    return characters, n_to_char, char_to_n  

# Create tensor data from corpus
def construct_data(corpus, char_to_n, max_seq = 100, stride = [1,6]):
    data_x = []
    data_y = []
    sequences = []
    max_seq+=1  
    print('Using:', len(corpus), 'files to train\n')

    for i in range(len(corpus)):
        text = corpus[i]['corpus']
        text_length = len(text)
        j = max_seq
        while j < text_length + stride[0]:
            k = min(j, text_length)          
            sequence = text[(k - max_seq):k] 
            encoded = np.array([char_to_n[x] for x in sequence]) 
            sequences.append(sequence)
            data_y.append(encoded[1:])
            data_x.append(encoded[:-1])
            j+=int(np.random.uniform(stride[0], stride[1]+1))       
    data_x = np.array(data_x) 
    data_y = np.array(data_y) 
    return shuffle(data_x, data_y)

def get_tensor_data(corpus_train, corpus_test, char_to_n, max_seq, stride ):
  train_x, train_y = construct_data(corpus_train, char_to_n, 
                                max_seq = max_seq, stride=stride)
  if len(corpus_test):
      test_x, test_y = construct_data(corpus_test, char_to_n, 
                                    max_seq = max_seq, stride=stride)
  else:
      test_x, test_y = None, None
  
  return train_x, train_y, test_x, test_y

def get_data():
    # We decided to use all data for training
    SPLIT = 1
    MAX_SEQ = 120
    STRIDE = [MAX_SEQ/2, MAX_SEQ] 

    poem_dir_path = '../data/poetry_data'
    poem_corpus = read_poems(poem_dir_path)

    corpus = clean_data(poem_corpus)

    characters, n_to_char, char_to_n =  get_vocabulary(corpus)

    words_mapping = {'characters': characters,
                    'n_to_char': n_to_char,
                    'char_to_n': char_to_n}

    indices = [i for i in range(len(corpus))]
    for_train = np.random.choice(indices, size=int(len(corpus)*SPLIT), replace=False)
    for_test = [i for i in indices if i not in for_train]
    corpus_train = [corpus[i] for i in for_train]
    corpus_test = [corpus[i] for i in for_test]

    train_x, train_y, test_x, test_y = get_tensor_data(corpus_train=corpus_train, corpus_test=corpus_test, char_to_n = char_to_n, max_seq=MAX_SEQ, stride=STRIDE)

    data = {'corpus': corpus,
            'words_mapping': words_mapping,
            'train_x': train_x ,
            'train_y': train_y,
            'test_x' : test_x,
            'test_y' : test_y}

    # save file
    with open('../data/processed/processed_poems.pickle', 'wb') as file:
        pickle.dump(data, file)
    print('Data saved in:', 'data/processed/processed_poems.pickle')

    return corpus_train, corpus_test